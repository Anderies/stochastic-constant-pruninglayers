{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSdVR6fBcJsu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3jRkX01cQdx"
   },
   "outputs": [],
   "source": [
    "__all__ = ['ResNet_StoDepth_lineardecay', 'resnet18_StoDepth_lineardecay', 'resnet34_StoDepth_lineardecay', 'resnet50_StoDepth_lineardecay', 'resnet101_StoDepth_lineardecay',\n",
    "           'resnet152_StoDepth_lineardecay']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4X-a8An1cX8X",
    "outputId": "810dfdd6-dc97-4a4f-f152-717e0abd91ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUtrdhNgchcX",
    "outputId": "9f286c5b-80dd-45c4-a1f2-56fb77e9aba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvjrCtc3cwYe"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    # \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    # \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "\n",
    "class StoDepth_BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, prob, multFlag, inplanes, planes, stride=1, downsample=None):\n",
    "        super(StoDepth_BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.prob = prob\n",
    "        self.m = torch.distributions.bernoulli.Bernoulli(torch.Tensor([self.prob]))\n",
    "        self.multFlag = multFlag\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x.clone()\n",
    "\n",
    "        if self.training:\n",
    "            if torch.equal(self.m.sample(),torch.ones(1)):\n",
    "\n",
    "                self.conv1.weight.requires_grad = True\n",
    "                self.conv2.weight.requires_grad = True\n",
    "\n",
    "                out = self.conv1(x)\n",
    "                out = self.bn1(out)\n",
    "                out = self.relu(out)\n",
    "                out = self.conv2(out)\n",
    "                out = self.bn2(out)\n",
    "\n",
    "                if self.downsample is not None:\n",
    "                    identity = self.downsample(x)\n",
    "\n",
    "                out += identity\n",
    "            else:\n",
    "                # Resnet does not use bias terms\n",
    "                self.conv1.weight.requires_grad = False\n",
    "                self.conv2.weight.requires_grad = False\n",
    "                \n",
    "                if self.downsample is not None:\n",
    "                    identity = self.downsample(x)\n",
    "\n",
    "                out = identity\n",
    "        else:\n",
    "            \n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.bn1(out)\n",
    "            out = self.relu(out)\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            if self.multFlag:\n",
    "                out = self.prob*out + identity\n",
    "            else:\n",
    "                out = out + identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class StoDepth_Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, prob, multFlag, inplanes, planes, stride=1, downsample=None):\n",
    "        super(StoDepth_Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.prob = prob\n",
    "        self.m = torch.distributions.bernoulli.Bernoulli(torch.Tensor([self.prob]))\n",
    "        self.multFlag = multFlag\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()\n",
    "\n",
    "        if self.training:\n",
    "            if torch.equal(self.m.sample(),torch.ones(1)):\n",
    "                self.conv1.weight.requires_grad = True\n",
    "                self.conv2.weight.requires_grad = True\n",
    "                self.conv3.weight.requires_grad = True\n",
    "\n",
    "                out = self.conv1(x)\n",
    "                out = self.bn1(out)\n",
    "                out = self.relu(out)\n",
    "\n",
    "                out = self.conv2(out)\n",
    "                out = self.bn2(out)\n",
    "                out = self.relu(out)\n",
    "\n",
    "                out = self.conv3(out)\n",
    "                out = self.bn3(out)\n",
    "\n",
    "                if self.downsample is not None:\n",
    "                    identity = self.downsample(x)\n",
    "\n",
    "                out += identity\n",
    "            else:\n",
    "                # Resnet does not use bias terms\n",
    "                self.conv1.weight.requires_grad = False\n",
    "                self.conv2.weight.requires_grad = False\n",
    "                self.conv3.weight.requires_grad = False\n",
    "\n",
    "                if self.downsample is not None:\n",
    "                    identity = self.downsample(x)\n",
    "\n",
    "                out = identity\n",
    "        else:\n",
    "            out = self.conv1(x)\n",
    "            out = self.bn1(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv3(out)\n",
    "            out = self.bn3(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            if self.multFlag:\n",
    "                out = self.prob*out + identity\n",
    "            else:\n",
    "                out = out + identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_StoDepth_lineardecay(nn.Module):\n",
    "\n",
    "    def __init__(self, block, prob_0_L, multFlag, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet_StoDepth_lineardecay, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.multFlag = multFlag\n",
    "        self.prob_now = prob_0_L[0]\n",
    "        self.prob_delta = prob_0_L[0]-prob_0_L[1]\n",
    "        self.prob_step = self.prob_delta/(sum(layers)-1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, StoDepth_lineardecayBottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, StoDepth_lineardecayBasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.prob_now, self.multFlag, self.inplanes, planes, stride, downsample))\n",
    "        self.prob_now = self.prob_now - self.prob_step\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.prob_now, self.multFlag, self.inplanes, planes))\n",
    "            self.prob_now = self.prob_now - self.prob_step\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
    "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-18 model.\n",
    "    # Args:\n",
    "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    # \"\"\"\n",
    "    model = ResNet_StoDepth_lineardecay(StoDepth_BasicBlock, prob_0_L, multFlag, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
    "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-34 model.\n",
    "    # Args:\n",
    "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    # \"\"\"\n",
    "    model = ResNet_StoDepth_lineardecay(StoDepth_BasicBlock, prob_0_L, multFlag, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "# UBAH JADI multFlag=False \n",
    "def resnet50_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
    "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-50 model.\n",
    "    # Args:\n",
    "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    # \"\"\"\n",
    "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        print(\"Program Pretrained\",pretrained)\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
    "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-101 model.\n",
    "    # Args:\n",
    "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    # \"\"\"\n",
    "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
    "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-152 model.\n",
    "    # Args:\n",
    "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    # \"\"\"\n",
    "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = resnet34_StoDepth_lineardecay()\n",
    "    x = torch.randn(2,3,224,224)\n",
    "    y = net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxlG45nRcz9-"
   },
   "outputs": [],
   "source": [
    "# %ls drive/MyDrive/\n",
    "\n",
    "model = torch.load('drive/MyDrive/ResNetModel/myResNetStokastik404-0.9418.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVwvojsHdrUP"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6n7RmUNmdyIf",
    "outputId": "c97e54f8-8bf3-4bd4-ffb6-614371323f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing dataset..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='drive/MyDrive/MyThesis/cifar-10-batches-py', train=True, download=True, transform=transform_train)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='drive/MyDrive/MyThesis/cifar-10-batches-py', train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2)    \n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "        'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zv78UinZd1Ti"
   },
   "outputs": [],
   "source": [
    "# print(model) \n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,weight_decay=1e-4,nesterov=True,dampening=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuZn8SQ6iJ3F"
   },
   "outputs": [],
   "source": [
    "for i,child in enumerate(model.children()):\n",
    "    print(i, \"======\" ,child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaZs3JxRiqGT"
   },
   "outputs": [],
   "source": [
    "# newModel = []\n",
    "# child_of_7 = []\n",
    "# for i,child in enumerate(model.children()):\n",
    "#     if i <= 6:\n",
    "#       newModel.append(child)\n",
    "#     elif i == 7:\n",
    "#       for j,data2 in enumerate(child.children()):\n",
    "#           child_of_7.append(data2)\n",
    "#     elif i > 7:\n",
    "#       newModel.append(child)\n",
    "  \n",
    "\n",
    "# # print(\"==========================\")\n",
    "# child_of_7_m = torch.nn.Sequential(child_of_7[0],child_of_7[1],child_of_7[2])\n",
    "# # print(\"==========================\")\n",
    "\n",
    "# insert_at = 7  # Index at which you want to insert item\n",
    "# newModel_b = newModel[:]   # Created copy of list \"a\" as \"b\".\n",
    "# newModel_b[insert_at:insert_at] =  torch.nn.Sequential(child_of_7_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFu_oRSeLDu7"
   },
   "outputs": [],
   "source": [
    "# class resnet_remove_layer(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         r_mode = model\n",
    "#         self.Conv1 = torch.nn.Sequential(*(list(r_mode.children())[0:7]))\n",
    "#         self.Conv2 = model.layer4[0] , model.layer4[1] , model.layer4[2] ,  torch.nn.Sequential(*(list(r_mode.children())[8:10]))\n",
    "#         # self.Conv3 = model.layer4[1]\n",
    "#         # self.Conv4 = model.layer4[2]\n",
    "#         # self.Conv5 = torch.nn.Sequential(*(list(r_mode.children())[8:10]))\n",
    "   \n",
    "#     def forward(self,x):\n",
    "#         out1 = self.Conv1(x)\n",
    "#         out2 = self.Conv2(out1)\n",
    "#         # out3 = self.Conv3(out2)\n",
    "#         # out4 = self.Conv4(out3)\n",
    "#         # out5 = self.Conv5(out2)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# net2 = resnet_remove_layer()\n",
    "# print(net2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws2sX-tVqW-o"
   },
   "source": [
    "# **TRAINING FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "675AWSmud5Ru"
   },
   "outputs": [],
   "source": [
    "info_train = []\n",
    "info_test = []\n",
    "\n",
    "def train(epoch,end_epoch):\n",
    "    best_acc = 0.9\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    model.train()\n",
    "    print(\"Epoch: \",epoch+1,\"||\",end_epoch)\n",
    "    with torch.set_grad_enabled(True):\n",
    "     for inputs, labels in trainloader:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        # correct += (predicted == labels).sum().item()\n",
    "        running_corrects += (predicted == labels.data).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = running_corrects / total\n",
    "\n",
    "    info_train.append({'epoch':epoch+1,'loss':epoch_loss,'acc':epoch_acc})    \n",
    "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'Training = ', epoch_loss, epoch_acc))\n",
    "    \n",
    "    test_epoch()\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "      acc_format_name = format(epoch_acc, \".4f\")\n",
    "      print(\"saved : \",acc_format_name)\n",
    "      torch.save(model,f'drive/MyDrive/ResNetModel/myResNetStokastik{epoch+1}-{acc_format_name}.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLII3grkqZsQ"
   },
   "source": [
    "# TEST **FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SrWl2-qqd6uD"
   },
   "outputs": [],
   "source": [
    "def test_epoch(model):\n",
    "    test_running_corrects = 0\n",
    "    test_running_loss = 0.0\n",
    "    total_test = 0\n",
    "    # model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for inputs_test,labels_test in testloader:\n",
    "          inputs_test = inputs_test.to(device)\n",
    "          labels_test = labels_test.to(device)\n",
    "          # print(\"check ==\",inputs_test)\n",
    "          outputs_test = model(inputs_test)\n",
    "          loss_test = criterion(outputs_test, labels_test)\n",
    "          _, pred_test = torch.max(outputs_test.data, 1)\n",
    "          total_test += labels_test.size(0)\n",
    "          \n",
    "          test_running_corrects += (pred_test == labels_test).sum().item()\n",
    "          test_running_loss += loss_test.item()\n",
    "\n",
    "          # print(test_running_corrects)\n",
    "          # print(total_test)\n",
    "\n",
    "          test_epoch_loss = test_running_loss / total_test\n",
    "          test_epoch_acc = test_running_corrects / total_test\n",
    "\n",
    "      # info_test.append({'epoch':epoch+1,'loss':test_epoch_loss,'acc':test_epoch_acc})\n",
    "\n",
    "      # print(test_epoch_loss,\" \",test_epoch_acc)\n",
    "      print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        'Test =', test_epoch_loss, test_epoch_acc))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8j_-SUdHqedx"
   },
   "source": [
    "# **START TRAINING AND TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxG3Y_jPd9Ay"
   },
   "outputs": [],
   "source": [
    "# start_epoch = 401\n",
    "# end_epoch = 500\n",
    "\n",
    "# import time\n",
    "# since = time.time()\n",
    "\n",
    "# for epoch in range(start_epoch,end_epoch):\n",
    "#     train(epoch,end_epoch)\n",
    "\n",
    "# print('Finished Training and Testing Process')\n",
    "# time_elapsed = time.time() - since\n",
    "# print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "#         time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vurRc-yeZ9Km"
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import torch\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "\n",
    "# gauth = GoogleAuth()           \n",
    "# drive = GoogleDrive(gauth)\n",
    "\n",
    "\n",
    "# with open('info_train.txt', 'w') as json_file:\n",
    "#     json.dump(info_train, json_file)\n",
    "\n",
    "# with open('info_test.txt', 'w') as json_file:\n",
    "#     json.dump(info_test, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxYbv2xla45E"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RC2RYUAJamqK"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "model_new = copy.deepcopy(model)\n",
    "def test_remove_layer():\n",
    "    model_new = copy.deepcopy(model)\n",
    "    \n",
    "    print(\"Without Removed Layer\")\n",
    "    result_5 = test_epoch(model)\n",
    "\n",
    "\n",
    "    print(\"CONV_4_2 Removed\")\n",
    "    del model_new.layer4[2]\n",
    "    result_1 = test_epoch(model_new)\n",
    "\n",
    "\n",
    "    print(\"CONV_4_1 Removed\")\n",
    "    del model_new.layer4[1]\n",
    "    result_2 = test_epoch(model_new)\n",
    "\n",
    "    \n",
    "    print(\"CONV_3_5 Removed\")\n",
    "    del model_new.layer3[5]\n",
    "    result_3 = test_epoch(model_new)\n",
    "\n",
    "    \n",
    "    print(\"CONV_3_4 Removed\")\n",
    "    del model_new.layer3[4]\n",
    "    result_4 = test_epoch(model_new)\n",
    "\n",
    "\n",
    "    print(\"CONV_3_3 Removed\")\n",
    "    del model_new.layer3[3]\n",
    "    result_5 = test_epoch(model_new)\n",
    "\n",
    "    print(\"CONV_3_2 Removed\")\n",
    "    del model_new.layer3[2]\n",
    "    result_6 = test_epoch(model_new)\n",
    "\n",
    "\n",
    "    print(\"CONV_3_1 Removed\")\n",
    "    del model_new.layer3[1]\n",
    "    result_6 = test_epoch(model_new)\n",
    "   \n",
    "    # return result_1,result_2,result_3,result_4,result_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3q8kJ9yVdrM6",
    "outputId": "11f09865-eacd-4b66-cf21-ea2474830c84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Removed Layer\n",
      "Test = Loss: 0.0879 Acc: 0.8841\n",
      "CONV_4_2 Removed\n",
      "Test = Loss: 0.0880 Acc: 0.8844\n",
      "CONV_4_1 Removed\n",
      "Test = Loss: 0.0883 Acc: 0.8826\n",
      "CONV_3_5 Removed\n",
      "Test = Loss: 0.0896 Acc: 0.8798\n",
      "CONV_3_4 Removed\n",
      "Test = Loss: 0.0971 Acc: 0.8819\n",
      "CONV_3_3 Removed\n",
      "Test = Loss: 0.1328 Acc: 0.8766\n",
      "CONV_3_2 Removed\n",
      "Test = Loss: 0.2294 Acc: 0.8389\n",
      "CONV_3_1 Removed\n",
      "Test = Loss: 0.4714 Acc: 0.2403\n"
     ]
    }
   ],
   "source": [
    "test_remove_layer()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNetStochasticCIFAR10EXPERIMENT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
