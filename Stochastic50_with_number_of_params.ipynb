{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ResNetStochasticCIFAR10EXPERIMENT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdVR6fBcJsu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3jRkX01cQdx"
      },
      "source": [
        "__all__ = ['ResNet_StoDepth_lineardecay', 'resnet18_StoDepth_lineardecay', 'resnet34_StoDepth_lineardecay', 'resnet50_StoDepth_lineardecay', 'resnet101_StoDepth_lineardecay',\n",
        "           'resnet152_StoDepth_lineardecay']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X-a8An1cX8X",
        "outputId": "80630080-8e43-4a9c-f1df-67301df04ad4"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUtrdhNgchcX",
        "outputId": "a667f4ab-e8e3-40a1-8b7e-5a652b53ccec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvjrCtc3cwYe"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    # \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    # \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class StoDepth_BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, prob, multFlag, inplanes, planes, stride=1, downsample=None):\n",
        "        super(StoDepth_BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.prob = prob\n",
        "        self.m = torch.distributions.bernoulli.Bernoulli(torch.Tensor([self.prob]))\n",
        "        self.multFlag = multFlag\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        identity = x.clone()\n",
        "\n",
        "        if self.training:\n",
        "            if torch.equal(self.m.sample(),torch.ones(1)):\n",
        "\n",
        "                self.conv1.weight.requires_grad = True\n",
        "                self.conv2.weight.requires_grad = True\n",
        "\n",
        "                out = self.conv1(x)\n",
        "                out = self.bn1(out)\n",
        "                out = self.relu(out)\n",
        "                out = self.conv2(out)\n",
        "                out = self.bn2(out)\n",
        "\n",
        "                if self.downsample is not None:\n",
        "                    identity = self.downsample(x)\n",
        "\n",
        "                out += identity\n",
        "            else:\n",
        "                # Resnet does not use bias terms\n",
        "                self.conv1.weight.requires_grad = False\n",
        "                self.conv2.weight.requires_grad = False\n",
        "                \n",
        "                if self.downsample is not None:\n",
        "                    identity = self.downsample(x)\n",
        "\n",
        "                out = identity\n",
        "        else:\n",
        "            \n",
        "\n",
        "            out = self.conv1(x)\n",
        "            out = self.bn1(out)\n",
        "            out = self.relu(out)\n",
        "            out = self.conv2(out)\n",
        "            out = self.bn2(out)\n",
        "\n",
        "            if self.downsample is not None:\n",
        "                identity = self.downsample(x)\n",
        "\n",
        "            if self.multFlag:\n",
        "                out = self.prob*out + identity\n",
        "            else:\n",
        "                out = out + identity\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class StoDepth_Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, prob, multFlag, inplanes, planes, stride=1, downsample=None):\n",
        "        super(StoDepth_Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.prob = prob\n",
        "        self.m = torch.distributions.bernoulli.Bernoulli(torch.Tensor([self.prob]))\n",
        "        self.multFlag = multFlag\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        identity = x.clone()\n",
        "\n",
        "        if self.training:\n",
        "            if torch.equal(self.m.sample(),torch.ones(1)):\n",
        "                self.conv1.weight.requires_grad = True\n",
        "                self.conv2.weight.requires_grad = True\n",
        "                self.conv3.weight.requires_grad = True\n",
        "\n",
        "                out = self.conv1(x)\n",
        "                out = self.bn1(out)\n",
        "                out = self.relu(out)\n",
        "\n",
        "                out = self.conv2(out)\n",
        "                out = self.bn2(out)\n",
        "                out = self.relu(out)\n",
        "\n",
        "                out = self.conv3(out)\n",
        "                out = self.bn3(out)\n",
        "\n",
        "                if self.downsample is not None:\n",
        "                    identity = self.downsample(x)\n",
        "\n",
        "                out += identity\n",
        "            else:\n",
        "                # Resnet does not use bias terms\n",
        "                self.conv1.weight.requires_grad = False\n",
        "                self.conv2.weight.requires_grad = False\n",
        "                self.conv3.weight.requires_grad = False\n",
        "\n",
        "                if self.downsample is not None:\n",
        "                    identity = self.downsample(x)\n",
        "\n",
        "                out = identity\n",
        "        else:\n",
        "            out = self.conv1(x)\n",
        "            out = self.bn1(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.bn2(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.conv3(out)\n",
        "            out = self.bn3(out)\n",
        "\n",
        "            if self.downsample is not None:\n",
        "                identity = self.downsample(x)\n",
        "\n",
        "            if self.multFlag:\n",
        "                out = self.prob*out + identity\n",
        "            else:\n",
        "                out = out + identity\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet_StoDepth_lineardecay(nn.Module):\n",
        "\n",
        "    def __init__(self, block, prob_0_L, multFlag, layers, num_classes=1000, zero_init_residual=False):\n",
        "        super(ResNet_StoDepth_lineardecay, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.multFlag = multFlag\n",
        "        self.prob_now = prob_0_L[0]\n",
        "        self.prob_delta = prob_0_L[0]-prob_0_L[1]\n",
        "        self.prob_step = self.prob_delta/(sum(layers)-1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, StoDepth_lineardecayBottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, StoDepth_lineardecayBasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.prob_now, self.multFlag, self.inplanes, planes, stride, downsample))\n",
        "        self.prob_now = self.prob_now - self.prob_step\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.prob_now, self.multFlag, self.inplanes, planes))\n",
        "            self.prob_now = self.prob_now - self.prob_step\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet18_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
        "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-18 model.\n",
        "    # Args:\n",
        "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    # \"\"\"\n",
        "    model = ResNet_StoDepth_lineardecay(StoDepth_BasicBlock, prob_0_L, multFlag, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
        "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-34 model.\n",
        "    # Args:\n",
        "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    # \"\"\"\n",
        "    model = ResNet_StoDepth_lineardecay(StoDepth_BasicBlock, prob_0_L, multFlag, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
        "    return model\n",
        "\n",
        "\n",
        "# UBAH JADI multFlag=False \n",
        "def resnet50_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
        "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-50 model.\n",
        "    # Args:\n",
        "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    # \"\"\"\n",
        "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        print(\"Program Pretrained\",pretrained)\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
        "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-101 model.\n",
        "    # Args:\n",
        "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    # \"\"\"\n",
        "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152_StoDepth_lineardecay(pretrained=False, prob_0_L=[1,0.5], multFlag=True, **kwargs):\n",
        "    # \"\"\"Constructs a ResNet_StoDepth_lineardecay-152 model.\n",
        "    # Args:\n",
        "    #     pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    # \"\"\"\n",
        "    model = ResNet_StoDepth_lineardecay(StoDepth_Bottleneck, prob_0_L, multFlag, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = resnet34_StoDepth_lineardecay()\n",
        "    x = torch.randn(2,3,224,224)\n",
        "    y = net(x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlG45nRcz9-"
      },
      "source": [
        "# %ls drive/MyDrive/\n",
        "\n",
        "model = torch.load('drive/MyDrive/ResNetModel/myResNetStokastik404-0.9418.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVwvojsHdrUP"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n7RmUNmdyIf",
        "outputId": "8a130981-d0ef-4755-aca8-2d2a40d33cac"
      },
      "source": [
        "print('==> Preparing dataset..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='drive/MyDrive/MyThesis/cifar-10-batches-py', train=True, download=True, transform=transform_train)\n",
        "\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='drive/MyDrive/MyThesis/cifar-10-batches-py', train=False, download=True, transform=transform_test)\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=4, shuffle=True, num_workers=2)    \n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "        'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing dataset..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv78UinZd1Ti"
      },
      "source": [
        "# print(model) \n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9,weight_decay=1e-4,nesterov=True,dampening=0)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuZn8SQ6iJ3F"
      },
      "source": [
        "for i,child in enumerate(model.children()):\n",
        "    print(i, \"======\" ,child)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaZs3JxRiqGT"
      },
      "source": [
        "# newModel = []\n",
        "# child_of_7 = []\n",
        "# for i,child in enumerate(model.children()):\n",
        "#     if i <= 6:\n",
        "#       newModel.append(child)\n",
        "#     elif i == 7:\n",
        "#       for j,data2 in enumerate(child.children()):\n",
        "#           child_of_7.append(data2)\n",
        "#     elif i > 7:\n",
        "#       newModel.append(child)\n",
        "  \n",
        "\n",
        "# # print(\"==========================\")\n",
        "# child_of_7_m = torch.nn.Sequential(child_of_7[0],child_of_7[1],child_of_7[2])\n",
        "# # print(\"==========================\")\n",
        "\n",
        "# insert_at = 7  # Index at which you want to insert item\n",
        "# newModel_b = newModel[:]   # Created copy of list \"a\" as \"b\".\n",
        "# newModel_b[insert_at:insert_at] =  torch.nn.Sequential(child_of_7_m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFu_oRSeLDu7"
      },
      "source": [
        "# class resnet_remove_layer(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         r_mode = model\n",
        "#         self.Conv1 = torch.nn.Sequential(*(list(r_mode.children())[0:7]))\n",
        "#         self.Conv2 = model.layer4[0] , model.layer4[1] , model.layer4[2] ,  torch.nn.Sequential(*(list(r_mode.children())[8:10]))\n",
        "#         # self.Conv3 = model.layer4[1]\n",
        "#         # self.Conv4 = model.layer4[2]\n",
        "#         # self.Conv5 = torch.nn.Sequential(*(list(r_mode.children())[8:10]))\n",
        "   \n",
        "#     def forward(self,x):\n",
        "#         out1 = self.Conv1(x)\n",
        "#         out2 = self.Conv2(out1)\n",
        "#         # out3 = self.Conv3(out2)\n",
        "#         # out4 = self.Conv4(out3)\n",
        "#         # out5 = self.Conv5(out2)\n",
        "        \n",
        "#         return x\n",
        "\n",
        "# net2 = resnet_remove_layer()\n",
        "# print(net2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2sX-tVqW-o"
      },
      "source": [
        "# **TRAINING FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "675AWSmud5Ru"
      },
      "source": [
        "info_train = []\n",
        "info_test = []\n",
        "\n",
        "def train(epoch,end_epoch):\n",
        "    best_acc = 0.9\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    model.train()\n",
        "    print(\"Epoch: \",epoch+1,\"||\",end_epoch)\n",
        "    with torch.set_grad_enabled(True):\n",
        "     for inputs, labels in trainloader:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "        running_corrects += (predicted == labels.data).sum().item()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / total\n",
        "        epoch_acc = running_corrects / total\n",
        "\n",
        "    info_train.append({'epoch':epoch+1,'loss':epoch_loss,'acc':epoch_acc})    \n",
        "    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "        'Training = ', epoch_loss, epoch_acc))\n",
        "    \n",
        "    test_epoch()\n",
        "\n",
        "    if epoch_acc > best_acc:\n",
        "      acc_format_name = format(epoch_acc, \".4f\")\n",
        "      print(\"saved : \",acc_format_name)\n",
        "      torch.save(model,f'drive/MyDrive/ResNetModel/myResNetStokastik{epoch+1}-{acc_format_name}.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLII3grkqZsQ"
      },
      "source": [
        "# TEST **FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrWl2-qqd6uD"
      },
      "source": [
        "def test_epoch(model):\n",
        "    test_running_corrects = 0\n",
        "    test_running_loss = 0.0\n",
        "    total_test = 0\n",
        "    # model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for inputs_test,labels_test in testloader:\n",
        "          inputs_test = inputs_test.to(device)\n",
        "          labels_test = labels_test.to(device)\n",
        "          # print(\"check ==\",inputs_test)\n",
        "          outputs_test = model(inputs_test)\n",
        "          loss_test = criterion(outputs_test, labels_test)\n",
        "          _, pred_test = torch.max(outputs_test.data, 1)\n",
        "          total_test += labels_test.size(0)\n",
        "          \n",
        "          test_running_corrects += (pred_test == labels_test).sum().item()\n",
        "          test_running_loss += loss_test.item()\n",
        "\n",
        "          # print(test_running_corrects)\n",
        "          # print(total_test)\n",
        "\n",
        "          test_epoch_loss = test_running_loss / total_test\n",
        "          test_epoch_acc = test_running_corrects / total_test\n",
        "\n",
        "      # info_test.append({'epoch':epoch+1,'loss':test_epoch_loss,'acc':test_epoch_acc})\n",
        "\n",
        "      params = count_parameters(model)\n",
        "      # print(test_epoch_loss,\" \",test_epoch_acc)\n",
        "      print('{} Loss: {:.4f} Acc: {:.4f} Params: {}'.format(\n",
        "        'Test =', test_epoch_loss, test_epoch_acc,params))\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j_-SUdHqedx"
      },
      "source": [
        "# **START TRAINING AND TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxG3Y_jPd9Ay"
      },
      "source": [
        "# start_epoch = 401\n",
        "# end_epoch = 500\n",
        "\n",
        "# import time\n",
        "# since = time.time()\n",
        "\n",
        "# for epoch in range(start_epoch,end_epoch):\n",
        "#     train(epoch,end_epoch)\n",
        "\n",
        "# print('Finished Training and Testing Process')\n",
        "# time_elapsed = time.time() - since\n",
        "# print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "#         time_elapsed // 60, time_elapsed % 60))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vurRc-yeZ9Km"
      },
      "source": [
        "# import json\n",
        "# import torch\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "\n",
        "# gauth = GoogleAuth()           \n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "# with open('info_train.txt', 'w') as json_file:\n",
        "#     json.dump(info_train, json_file)\n",
        "\n",
        "# with open('info_test.txt', 'w') as json_file:\n",
        "#     json.dump(info_test, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec__TOvm2AQb",
        "outputId": "1cbfb2aa-9cb4-480b-9dd2-833f0726f5f2"
      },
      "source": [
        "from torchsummary import summary\n",
        "# summary(resnet, (3, 224, 224),print_summary=True)\n",
        "# print(count(resnet))\n",
        "# resnet.count_params()\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    # print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "    \n",
        "params = count_parameters(model)\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Trainable Params: 12911690\n",
            "12911690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxYbv2xla45E"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC2RYUAJamqK"
      },
      "source": [
        "import copy\n",
        "model_new = copy.deepcopy(model)\n",
        "def test_remove_layer():\n",
        "    model_new = copy.deepcopy(model)\n",
        "    \n",
        "    print(\"Without Removed Layer\")\n",
        "    result_5 = test_epoch(model)\n",
        "    \n",
        "\n",
        "    print(\"CONV_4_2 Removed\")\n",
        "    del model_new.layer4[2]\n",
        "    result_1 = test_epoch(model_new)\n",
        "\n",
        "\n",
        "    print(\"CONV_4_1 Removed\")\n",
        "    del model_new.layer4[1]\n",
        "    result_2 = test_epoch(model_new)\n",
        "\n",
        "    \n",
        "    print(\"CONV_3_5 Removed\")\n",
        "    del model_new.layer3[5]\n",
        "    result_3 = test_epoch(model_new)\n",
        "\n",
        "    \n",
        "    print(\"CONV_3_4 Removed\")\n",
        "    del model_new.layer3[4]\n",
        "    result_4 = test_epoch(model_new)\n",
        "\n",
        "\n",
        "    print(\"CONV_3_3 Removed\")\n",
        "    del model_new.layer3[3]\n",
        "    result_5 = test_epoch(model_new)\n",
        "\n",
        "    print(\"CONV_3_2 Removed\")\n",
        "    del model_new.layer3[2]\n",
        "    result_6 = test_epoch(model_new)\n",
        "\n",
        "\n",
        "    print(\"CONV_3_1 Removed\")\n",
        "    del model_new.layer3[1]\n",
        "    result_6 = test_epoch(model_new)\n",
        "   \n",
        "    # return result_1,result_2,result_3,result_4,result_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q8kJ9yVdrM6",
        "outputId": "ebd1bf23-91c0-4b29-962c-0012a61ad9f7"
      },
      "source": [
        "test_remove_layer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Without Removed Layer\n",
            "Total Trainable Params: 12911690\n",
            "Test = Loss: 0.0879 Acc: 0.8841 Params: 12911690\n",
            "CONV_4_2 Removed\n",
            "Total Trainable Params: 12905546\n",
            "Test = Loss: 0.0880 Acc: 0.8844 Params: 12905546\n",
            "CONV_4_1 Removed\n",
            "Total Trainable Params: 8442954\n",
            "Test = Loss: 0.0883 Acc: 0.8826 Params: 8442954\n",
            "CONV_3_5 Removed\n",
            "Total Trainable Params: 7325770\n",
            "Test = Loss: 0.0896 Acc: 0.8798 Params: 7325770\n",
            "CONV_3_4 Removed\n",
            "Total Trainable Params: 7322698\n",
            "Test = Loss: 0.0971 Acc: 0.8819 Params: 7322698\n",
            "CONV_3_3 Removed\n",
            "Total Trainable Params: 7319626\n",
            "Test = Loss: 0.1328 Acc: 0.8766 Params: 7319626\n",
            "CONV_3_2 Removed\n",
            "Total Trainable Params: 6202442\n",
            "Test = Loss: 0.2294 Acc: 0.8389 Params: 6202442\n",
            "CONV_3_1 Removed\n",
            "Total Trainable Params: 5085258\n",
            "Test = Loss: 0.4714 Acc: 0.2403 Params: 5085258\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}